Web-based Supplementary Materials for “Evaluating
independent component analyses with an application to
resting-state fMRI,” by Benjamin B. Risk, David S. Matteson,
David Ruppert, Ani Eloyan, and Brian S. Caffo

Web Appendix A: Simulation Studies
A.1 The Infomax algorithm
We are not aware of functions or packages in R that implement the Infomax algorithm
(Bell and Sejnowski 1995). We offer an alternative to Matlab code (http://cnl.salk.
edu/~tewon/ICA/code.html), but with a few modifications that decrease computation
time. First, we use the full data (the so-called offline algorithm) in each iteration rather
than an online algorithm with batches. Secondly, we use an adaptive method to choose
the step size (based upon Bernaards and Jennrich 2005), which speeds up convergence.
We also omitted the bias term (intercept) included in the original formulation because we
centered our data. R code implementing the Infomax algorithm and example simulations
are available in <EvaluatingICA_Rsources.R> and <EvaluatingICA_Examples.R> in the
Supplementary Materials.

A.2 The ProDenICA algorithm
We made small modifications in the simulated data analysis in order to use the R-package
ProDenICA. When the IC density was heavy-tailed (e.g., t-distribution with df = 3 or

1

df = 5), the algorithm sometimes failed in the density estimation step. These issues were
resolved by removing one or more of the most extreme outliers.
It should be noted that the ‘restarts’ option in the ProDenICA() function evaluates
the objective function at N random matrices, determines the matrix with the highest
negentropy, and then initiates the ProDenICA algorithm with this single matrix. We found
that ProDenICA() should instead be initiated using multiple random matrices because a
single initial value may have a relatively high initial negentropy but be in a basin with a
local maximum.
Another issue that arose is that ProDenICA() produced an error when using the whitening option with Q < Tr . This issue was resolved by supplying ProDenICA() with an initial
unmixing matrix (rather than relying upon the default).
Lastly, we found that when using the log cosh nonlinearity (ProDenICA() provides a
function that replicates fastICA()), the negentropy measure was not correct; it simply
calculated the mean of

1
α

log cosh(αs). It should instead apply the formula in Equation 6

of the manuscript.

A.3 Simulated data
We simulated the mixing matrix A using the mixmat() function from the R package ProDenICA (Hastie and Tibshirani 2010), which ensures the condition number is between 1
and 2 by simulating a Q × Q matrix with iid entries from a standard normal, taking the
SVD, then generating random eigenvalues from the uniform(1,2) distribution, and defining
A as the product of the left eigenvector, these new eigenvalues, and the right eigenvector.
We conducted 100 simulations with V = 1, 024 samples for each component. Twenty-five
initial values were used for the iterative methods, where initial values were randomly selected from a latin hypercube using the angular (Givens) parameterization, with θq ∈ [0, π]
for q = 1, . . . , Q(Q − 1)/2 − 1 and θQ(Q−1)/2 ∈ [0, π/2]. Data were simulated from eighteen
distributions using rjordan() in the ProDenICA package (Hastie and Tibshirani 2010;
Web Figure 1).

2

Web Figure 1: Distributions used in simulations, which include the t-distribution with
df =3, double exponential, uniform, t-distribution with df =5, exponential, a mixture of
exponentials, and numerous mixtures of normals. Note that a, b, d, and e are superGaussian, while c and f - r are sub-Gaussian.

c

d

ex

kx

i

m
x

n
x
fun.jordan(x)

fun.jordan(x)

fun.jordan(x)

x
fun.jordan(x)

fun.jordan(x)

l

q
x

r

x
fun.jordan(x)

fun.jordan(x)

p
x
fun.jordan(x)

j

x

x

o
x

f

x
fun.jordan(x)

h
x
fun.jordan(x)

g
x

fun.jordan(x)

Index
fun.jordan(x)

Index

b
fun.jordan(x)

1

fun.jordan(x)

a

3

Web Table 1: The 0.025, 0.500, and 0.975 quantiles of computation times (in seconds)
based on 100 simulations with 25 initial values per simulation. Quantiles are based on the
pooled sample of 2,500 computation times for all methods except for JADE, which is not
initialized with multiple starting values and is consequently based on 100 samples.
Q
5
5
5
10
10
10
20
20
20

Quantile
0.025
0.500
0.975
0.025
0.500
0.975
0.025
0.500
0.975

FastICA
0.01
0.03
1.58
0.04
0.34
2.85
1.11
7.46
27.07

Infomax
1.28
3.19
5.95
5.88
11.69
13.05
18.75
25.36
29.02

JADE
0.02
0.02
0.05
0.10
0.17
0.27
2.41
3.98
10.00

ProDenICA
3.43
5.84
30.67
11.70
28.75
267.23
95.66
544.92
2478.45

A.4 Notes on the minimum distance measure
We adapt the minimum distance (MD) measure (Ilmonen et al. 2010), which was defined for
c (i) when the true unmixing matrix, W, is known. We apply the measure
some estimate W
to two arbitrary square matrices B(i) and B(j) . Let P denote the set of Q × Q signed
permutation matrices and C the set of Q × Q full-rank diagonal matrices. Then define the
set of scaled permutation matrices K = {K : K = P± C, ∀ P± ∈ P, C ∈ C}. Then the
minimum distance measure between two matrices B(i) and B(j) is

dM D (B(i) , B(j) ) = √

1
inf || KB(i) B−1
(j) − Id ||F
Q − 1 K∈K

where || · ||F denotes the Frobenius norm. Code implementing this measure is available in
the R package JADE (Nordhausen et al. 2011).

A.5 Computation times
We conducted our simulations on a cluster of 28 Dell PowerEdge 2650 servers with 8
processors per server, where each processor was 2.66 GHz. We used the R package snow
(Tierney et al. 2011) to conduct simulations in parallel. Computation times are presented
in Web Table 1.

4

Web Appendix B: Matching ICs
Our approach to matching ICs follows a modification of the Hungarian (Kuhn-Munkres)
algorithm (Tichavsky and Koldovsky 2004), and here we describe the modification in detail.
b k ∈ RV ×Q and S
b l ∈ RV ×Q , the ith estimate from method
Suppose we want to compare S
(i)
(j)
k and the jth estimate from method l. Hereafter, we drop the k and l superscripts to
simplify notation, noting that the estimates may or may not be from the same method.
b (i) is in canonical form, as defined in Section 4.2. We refer to the canonically
Assume that S
b (i) as the template. Let S
b (i),q be the qth column of S
b (i) and S
b (j),r be the rth
ordered S
b (j) , and let || · || denote the Euclidean norm. Create a Q × Q distance (cost)
column from S
matrix C between the components with elements


b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || ,
cq,r = min ||S

and define the matrix B with

bq,r =




−1


 1



b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || = ||S
b (i),q + S
b (j),r ||,
if min ||S


b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || = ||S
b (i),q − S
b (j),r ||.
if min ||S

Let S be the set of all permutations of the integers 1 to Q, where for some σ ∈ S, we denote
the permutation σ = (σ(1), . . . , σ(Q)). We then use the Hungarian algorithm (Kuhn 1955)
to identify the set such that
σ ∗ = argmin
σ∈S

Q
X

cq,σ(q) .

q=1

Then define the signed permutation matrix P1 with entries pq,aq = bq,aq at row q and
b (i) − S
b (j) P0 ||F .
column aq , and 0 otherwise. Note that P1 is equivalent to argmin || S
±
P± ∈P

The method used here to match ICs creates a one-to-one mapping of components. Note
that when multiple ICs are being compared, the matching algorithm may be sensitive to
the choice of template. In our application, we found that using the estimates from JADE,
Infomax, or ProDenICA as the template with one-at-a-time matching resulted in the same
ordering as using the FastICA estimate as the template. In situations in which ICs from
more than two estimates differ greatly, a method to simultaneously match all ICs could be
5

Web Table 2. Subject diagnosis by site in the ADHD-200 Sample: Typ=Typically Developing; ADHD-C=ADHD-Combined; ADHD-H/Im=ADHD-Hyperactive and Impulsive;
ADHD-In=ADHD-Inattentive; WH= Withheld.
Site
Bradley Hospital/Brown University
Kennedy Krieger Institute
NeuroIMAGE Sample
NYU Child Study Center
Oregon Health & Science University
Peking University
University of Pittsburgh
Washington University in St. Louis
Total

Typ
0
61
23
99
42
116
89
61
491

ADHD-C
0
16
18
77
23
29
0
0
163

ADHD-H/Im
0
1
6
2
2
0
0
0
11

ADHD-In
0
5
1
44
12
49
0
0
111

WH
26
11
25
41
34
51
9
0
197

pursued.

Web Appendix C: Group ICA of the ADHD-200 Sample
C.1 Resting-state fMRI dataset
Data were selected for analysis from the ADHD-200 Data Sample, which consists of rsfMRI data from children and adolescents (ages 7-21) from 8 independent sites comprising
491 typically developing subjects and 285 that were diagnosed with ADHD (Web Table 1).
Subjects were diagnosed with three ADHD subtypes: Inattentive; Hyperactive and Impulsive; and Combined (Hyperactive/Impulsive and Inattentive). However, there were only a
total of 11 subjects with ADHD-Inattentive, and half the sites did not have subjects with
this diagnosis.
We restricted our analysis to (1) subjects with no recorded history of drug therapy;
(2) subjects that were right-hand dominant; (3) images with no quality control flags; and
(4) subjects that were either ADHD-Combined or ADHD-Inattentive (but not ADHDHyperactive and Impulsive). Subjects were classified using either (1) the ADHD Rating
Scale IV, (2) Conner’s Parent Rating Scale-Revised (Long Version), or (3) Conner’s Rating
Scale, 3rd edition. Within these scales, there was a small degree of overlap in the intermediate values between subjects diagnosed as typically developing and subjects diagnosed
with ADHD, whereas individuals with low values were strictly labeled typically developing

6

Web Table 3. Subjects used in analysis. Typ=Typically Developing; ADHD-C=ADHDCombined; ADHD-In=ADHD-Inattentive.
Site
Peking University
Kennedy Krieger Institute
NYU Child Study Center
Oregon Health & Science University
Total

Typ
86
40
56
24
206

ADHD-C
13
7
16
8
44

ADHD-H/Im
0
0
0
0
0

ADHD-In
19
3
11
1
34

WH
0
0
0
0
0

and individuals with high values were strictly diagnosed with ADHD. We excluded subjects
with scores that we deemed borderline, that is, both control and ADHD subjects that were
near the threshold at which ADHD was diagnosed. Specifically, we excluded subjects with
ADHD Rating Scale IV values between 36 and 45; Conner’s Parent Rating Scale-Revised
(Long Version) between 56 and 65; or Conner’s Rating Scale between 55 and 66 (Web Table
2).
Details of the primary image processing pipeline were previously reported (Section 2.1,
Eloyan et al. 2012). Processing followed the functional connectome processing scripts on
the FCP/INDI site (Mennes et al. 2012). In addition, we aggregated the MNI 152 T1 3 mm
template to result in 6 × 6 × 6 mm voxels. We retained the 6 × 6 × 6 mm voxels for which
all eight of the voxels in the MNI 152 T1 3mm template were brain tissue. This resulted in
V = 7, 825 for all subsequent analyses. For subjects in which there were multiple scanning
sessions, we only used the first session.
We also used our own whitening function to produce the input data for all algorithms,
as provided in <EvaluatingICA_Rsources.R>. This ensured that Ŵ and Ŝ were always
defined equivalently. Note that the functions fastICA() and JADE() automatically whiten
data; consequently, we modified the source code to prevent additional whitening.

C.2 Differences Between Algorithms
We compared the unmixing matrices from FastICA, Infomax, JADE, and ProDenICA using
the MD measure, the Amari measure, and the Frobenius distance between matched unmixing matrices. To aid in our interpretation of the magnitude of differences between mixing
matrices, we simulated the distribution of these three measures for randomly generated

7

orthogonal matrices using two methods. First, orthogonal matrices were generated with
columns equal to the eigenvectors from the spectral decompositions of randomly generated
matrices following a Wishart distribution with covariance equal to the identity matrix and
V degrees of freedom. Second, we simulated uniformly distributed Givens rotation angles
θi ∈ [−π, π] for i = 1, . . . , Q(Q−1)/2, and then converted the angles to orthogonal matrices
(Web Table 4).
Web Table 4. Distance and measures between unmixing matrices by method for the rsfMRI study. Here, the SVD mixing matrix is taken to be the identity matrix. MD =
Minimum Distance measure. Mean and 1% Wishart denote the mean and 1% quantiles,
respectively, of each measure from matrices randomly generated via the SVD of iid Wishart
matrices. Mean and 1% unif denote the corresponding statistics for matrices generated
from the angular parametrization of orthogonal matrices with angles uniformly distributed
in [−π, π].

Method.1
Mean: Wishart 1
1%: Wishart 1
Mean: Unif 1
1%: Unif 1
SVD
SVD
SVD
SVD
FastICA
FastICA
FastICA
Infomax
Infomax
JADE

Method.2
Wishart 2
Wishart 2
Unif 2
Unif 2
fastICA
Infomax
JADE
ProDenICA
Infomax
JADE
ProDenICA
JADE
ProDenICA
ProDenICA

Amari
0.35
0.31
0.26
0.22
0.36
0.36
0.35
0.33
0.01
0.06
0.06
0.06
0.06
0.07

MD
0.90
0.88
0.85
0.80
0.91
0.91
0.90
0.89
0.07
0.38
0.41
0.39
0.42
0.41

Frobenius
6.31
5.92
6.32
5.76
6.30
6.33
6.30
6.29
0.29
1.75
1.89
1.80
1.93
1.85

In Web Table 5, we present false discovery rate (FDR) adjusted p-values from twosample Kolmogorov-Smirnov tests for equality in distribution between ICs estimated using
the SVD, FastICA, Infomax, and ProDenICA. In multiple hypothesis testing, the FDR is
the expected proportion of false positives among the rejected null hypotheses, and controlling the FDR leads to more powerful testing procedures than controlling the family-wise error rate (Benjamini and Hochberg 1995). For each p-value, we calculated an FDR-adjusted
p-value, called a q-value (Storey 2002): let G denote the total number of tests and p(g)

8

denote the gth order statistic from the set of all G p-values, and define the q-value
p∗(g)


= min


G
∗
∗
, . . . , p(G) , 1 .
p ,p
g (g) (g+1)

In typical applications, p∗(g) is an estimate of the minimum proportion of false positives given
that at least one rejection occurs, where the minimum is taken over all rejection regions
containing [0, p(g) ]. Here, we use the FDR-adjusted p-values as a measure of the difference
between IC distributions since the test statistics were based on spatially dependent data.
Web Table 5. FDR-adjusted p-values from two-sample Kolmogorov-Smirnov statistics.
Blank entries indicate FDR-adjusted p < 0.0001.
Method1
SVD
SVD
SVD
SVD
FastICA
FastICA
FastICA
Infomax
Infomax
JADE
Method1
SVD
SVD
SVD
SVD
FastICA
FastICA
FastICA
Infomax
Infomax
JADE

Method2
FastICA
Infomax
JADE
ProDenICA
Infomax
JADE
ProDenICA
JADE
ProDenICA
ProDenICA
Method2
FastICA
Infomax
JADE
ProDenICA
Infomax
JADE
ProDenICA
JADE
ProDenICA
ProDenICA

IC 1

IC 2

IC 3

0.9826
0.6165
0.0658
0.4688
0.1370
0.2807
IC 11

0.2733
0.0101
0.0166

0.1277

IC 12

IC 13

0.0878

0.4890
0.2136

0.3943

IC 4

IC 5

IC 6

IC 7

IC 8

IC 9

IC 10

0.5650
0.0001
0.1277

0.3543
0.0004
0.0002

0.4036
0.0222

0.1811

0.0005

IC 14

0.0556
0.2421
0.0451
0.1574
0.2354
0.0254
IC 15

IC 16

IC 17

0.1105
0.0003
0.0053
0.0004
0.0254
0.0265
IC 19

0.9481
0.0129
0.0129
0.0024
0.0027
0.1415
IC 20

0.3851
0.0380

0.9826
0.1068

0.4225
0.0101

0.0018
0.7906
0.1866

0.9826
0.0006

0.2867

0.4130

0.0112

0.0433

0.0002

0.0348

0.0002

0.4788

0.2660

0.9826
0.2867

0.0556
0.0002
IC 18
0.0004
0.0003
0.0002

0.0304

We also present density plots for each IC and each method. Densities were estimated
using a Gaussian kernel. For each component, a bandwidth was determined for the estimate
from FastICA, Infomax, JADE, and ProDenICA, respectively, using the method of Sheather
and Jones (1991), and then these four bandwidths were averaged, and finally the densities
were estimated with bandwidth fixed at this average. Thus, for a given component, the
densities for each of the methods were estimated using the same bandwidth.

9

Web Figure 2. Density plots of ICs for FastICA, Infomax, JADE, and ProDenICA. Values
on the x-axis correspond to the standardized BOLD signal. The sample skewness and
kurtosis from the FastICA estimates are included in the plot area.

2

4

6

8

6

4

0

2

4

6

6

8

0.6

6

8

0.6
2

4

6

0.8

skew = 0.28
kurt = 7.96

skew = 1.08
kurt = 7.06

−6

−4

−2

0

2

4

6

IC 20
N = 7825 Bandwidth = 0.09276
skew = 0.184
kurt = 7.79

0.6
Density

0.4

Density
5

4

0.2
0

0.0

0.2

0.2
0

2

IC 16
N = 7825 Bandwidth = 0.05645

IC 19
N = 7825 Bandwidth = 0.1003

0.0
−5

0

0.0
−2

0.6

0.6
0.4

Density

0.0
4

−2

0.4

skew = 1.32
kurt = 7.3

−4

0.2

0.4
0.2
0.0

2

6

skew = 2.01
kurt = 11.7

6

0.6
−2

skew = 0.618
kurt = 9.46

0

4

0.2
2

0.0
−4

skew = 0.959
kurt = 7.1

0.6

0

IC 15
N = 7825 Bandwidth = 0.04588

0.2

skew = 1.47
kurt = 9.12

IC 18
N = 7825 Bandwidth = 0.08463

−2

2

IC 12

0.0
−6 −4 −2

IC 17
N = 7825 Bandwidth = 0.06634

−4

0

0.4

Density

6

Density

0.4

Density

6

1.0
−2

N = 7825 Bandwidth = 0.05385

0.4
4

0.2
4

skew = 3.12
kurt = 16.9

8

0.0
2

0.0
2

0.0
1.0

4

skew = 2.36
kurt = 13.7

IC 14
N = 7825 Bandwidth = 0.04612
0.6

0.8

0

0.6
0.4

0

8

0.8
2

IC 11

skew = 2.41
kurt = 10.8

−2

0.0

−2

6

0.2
0

Density

8

4

IC 8

N = 7825 Bandwidth = 0.05744

0.4

6

2

0.8

1.0
4

0

N = 7825 Bandwidth = 0.03797

0.0
−2

0.8
0.6

Density

2

skew = 1.51
kurt = 9.04

−4
0.8

skew = 3.17
kurt = 17.7

0.2
0

0.2

Density

Density

−2

0.6

Density

0

IC 10

IC 13
N = 7825 Bandwidth = 0.05652

Density

10

0.2
−2

N = 7825 Bandwidth = 0.06127

0.0

0.0
−4 −2

Density

8

0.0
−4

0.4

0.6
0.4

skew = 2.58
kurt = 15.3

6

0.8

10

4

IC 7

0.4

8

2

1.2

6

0

N = 7825 Bandwidth = 0.04054

0.8

0.8
0.6
0.4

Density

4

IC 9

0.2

Density

Density

skew = 3.38
kurt = 19.5

0.2
2

0.5
−2

0.0
0

0.8

1.0

−2

Density

0.0

10

skew = 4.37
kurt = 27.8

0.4

5

IC 6

N = 7825 Bandwidth = 0.05009

1.5

1.5
Density

0.5
0

N = 7825 Bandwidth = 0.06753

1.0
0.8
0.6
0.4
0.0

0.2

Density

Density

skew = 4.06
kurt = 27.9

1.0

0.8
0.6

25

Density

20

Density

15

1.0

10

IC 5

skew = 4.37
kurt = 29.1

0.6

5

skew = 4.67
kurt = 35.8

0.4

0

N = 7825 Bandwidth = 0.07026

IC 4

0.8

−5

IC 3

0.4

Density

0.4
0.0

skew = 8.54
kurt = 133

0.2

0.6

FastICA
Infomax
JADE
ProDenICA

0.2

Density

Density

IC 2

0.0

0.8

IC 1

−5

0

5

−6

−4

−2

0

2

4

6

Std. BOLD

Std. BOLD

Std. BOLD

Std. BOLD

N = 7825 Bandwidth = 0.07138

N = 7825 Bandwidth = 0.1037

N = 7825 Bandwidth = 0.07738

N = 7825 Bandwidth = 0.07431

10

Web Figure 3. Estimated ICs. Clockwise from the top-left: IC 3 (parts of default network),
IC 4 (parts of the visual cortex), IC 13 (strong lateralization for FastICA and Infomax
but not JADE and ProDenICA), and IC 20 (strong lateralization in all methods; areas
associated with memory).
fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

Selected resting-state networks
Web Figure 3 presents images for selected ICs from the group ICA of the ADHD-200 Data
Sample. Images were thresholded to retain voxels with values greater than the 97.5%
quantile. Slices were chosen to approximately maximize the number of visible activated
voxels.
We estimated ICs from a single individual randomly chosen from the ADHD-200 data
(subject ID 3446674.1.1.pek2). We matched the FastICA estimates from this individual to
the skewness-ordered FastICA estimates of the group ICs, and then matched the ICs from
Infomax, JADE, and ProDenICA to these re-ordered FastICA results. Selected ICs are
presented in Web Figure 4.

11

Web Figure 4. Estimated ICs for a single subject randomly chosen from the ADHD200
dataset (subject ID 3446674.1.1.pek2). Clockwise from the top-left: IC 3 (parts of default
network), IC 4 (medial areas of the visual cortex), IC 13, and IC 20 (strong lateralization
in all methods; areas associated with memory).
fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

fastICA

Infomax

JADE

ProDenICA

References
Bell, A. J. and Sejnowski, T. J. (1995). An information-maximization approach to blind
separation and blind deconvolution. Neural computation 7, 1129–1159.
Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: a practical
and powerful approach to multiple testing. Journal of the Royal Statistical Society, Series
B (Methodological) pages 289–300.
Bernaards, C. A. and Jennrich, R. I. (2005). Gradient projection algorithms and software for
arbitrary rotation criteria in factor analysis. Educational and Psychological Measurement
65, 676–696.
Eloyan, A., Muschelli, J., Nebel, M. B., Liu, H., Han, F., Zhao, T., Barber, A., Joel, S.,
Pekar, J. J., Mostofsky, S., and Caffo, B. S. (2012). Automated diagnoses of attention
deficit hyperactive disorder using magnetic resonance imaging. Frontiers in Systems
Neuroscience 6, 1–9.
12

Hastie, T. and Tibshirani, R. (2010). ProDenICA: Product Density Estimation for ICA
using tilted Gaussian density estimates. R package version 1.0.
Ilmonen, P., Nordhausen, K., Oja, H., and Ollila, E. (2010). A new performance index
for ICA: properties, computation and asymptotic analysis. Latent Variable Analysis and
Signal Separation pages 229–236.
Kuhn, H. W. (1955). The Hungarian Method for the assignment problem. Naval Research
Logistics Quarterly 2, 83 – 97.
Mennes, M., Biswal, B., Castellanos, F. X., and Milham, M. P. (2012). Making data sharing
work: The FCP/INDI experience. NeuroImage .
Nordhausen, K., Cardoso, J. F., Oja, H., and Ollila, E. (2011). JADE: JADE and ICA
performance criteria. R package version 1.0-4.
Sheather, S. J. and Jones, M. C. (1991). A reliable data-based bandwidth selection method
for kernel density estimation. Journal of the Royal Statistical Society. Series B (Methodological) pages 683–690.
Storey, J. D. (2002). A direct approach to false discovery rates. Journal of the Royal
Statistical Society: Series B (Statistical Methodology) 64, 479–498.
Tichavsky, P. and Koldovsky, Z. (2004). Optimal pairing of signal components separated
by blind techniques. Signal Processing Letters, IEEE 11, 119–122.
Tierney, L., Rossini, A. J., Li, N., and Sevcikova, H. (2011). snow: Simple Network of
Workstations. R package version 0.3-8.

13

