Web-based Supplementary Materials for “Evaluating
independent component analyses with an application to
resting-state fMRI data,” by Benjamin B. Risk, David S.
Matteson, David Ruppert, Ani Eloyan, and Brian S. Caffo

January 9, 2013

s

Web Appendix A: Simulation Studies
A.1 The Infomax Algorithm
We are not aware of functions or packages in R that implement the Infomax algorithm
(Bell and Sejnowski 1995). We offer an alternative to Matlab code (http://cnl.salk.
edu/~tewon/ICA/code.html), but with a few modifications that decrease computation
time. First, we use the full data (the so-called offline algorithm) in each iteration rather
than an online algorithm with batches. Secondly, we use an adaptive method to choose
the step size (based upon Bernaards and Jennrich 2005), which speeds up convergence.
We also omitted the bias term (intercept) included in the original formulation because we
centered our data. R code implementing the Infomax algorithm and example simulations
are available in <EvaluatingICA_Rsources.R> and <EvaluatingICA_Examples.R> in the
Supplementary Materials.

1

A.2 Notes on using ProDenICA
We made small modifications in the simulated data analysis in order to use the R-package
ProDenICA. When the IC density was heavy-tailed (e.g., t-distribution with df = 3 or
df = 5), the algorithm sometimes failed in the density estimation step. These issues were
resolved by removing one or more of the most extreme outliers.
It should be noted that the ‘restarts’ option in the ProDenICA function evaluates the
objective function at N random matrices, determines the matrix with the highest negentropy, and then initiates ProDenICA with this single matrix. We found that ProDenICA
should instead be initiated using multiple random matrices because a single initial value
may have a relatively high initial negentropy but be in a basin with a local maximum.
Another issue that arose is that ProDenICA produced an error when using the whitening
option with Q < Tr . This issue was resolved by supplying ProDenICA with an initial
unmixing matrix (rather than relying upon the default).
Lastly, we found that when using the log cosh nonlinearity (ProDenICA provides a
function that replicates fastICA), the negentropy measure was not correct; it simply calculated the mean of

1
α

log cosh(αs). It should instead apply the formula in Equation 6 of the

manuscript.

A.3 Simulated Data
We simulated the mixing matrix A using the mixmat() function from the R package ProDenICA (Hastie and Tibshirani 2010), which ensures the condition number is between 1
and 2 by simulating a Q × Q matrix with iid entries from a standard normal, taking the
SVD, then generating random eigenvalues from the uniform(1,2) distribution, and defining
A as the product of the left eigenvector, these new eigenvalues, and the right eigenvector.
We conducted 100 simulations with V = 1, 024 samples for each component. Twenty-five
initial values were used for the iterative methods, where initial values were randomly selected from a latin hypercube using the angular (Givens) parameterization, with θq ∈ [0, π]
for q = 1, . . . , Q(Q − 1)/2 − 1 and θQ(Q−1)/2 ∈ [0, π/2]. Data were simulated from eighteen
distributions using ProDenICA (Hastie and Tibshirani 2010; Web Figure 1).

2

Web Figure 1: Distributions used in simulations, which include the t-distribution with
df =3, double exponential, uniform, t-distribution with df =5, exponential, a mixture of
exponentials, and numerous mixtures of normals

c

d

ex

kx

i

m
x

n
x
fun.jordan(x)

fun.jordan(x)

fun.jordan(x)

x
fun.jordan(x)

fun.jordan(x)

l

q
x

r

x
fun.jordan(x)

fun.jordan(x)

p
x
fun.jordan(x)

j

x

x

o
x

f

x
fun.jordan(x)

h
x
fun.jordan(x)

g
x

fun.jordan(x)

Index
fun.jordan(x)

Index

b
fun.jordan(x)

1

fun.jordan(x)

a

3

Web Table 1: The 0.025, 0.500, and 0.975 quantiles of computation times (in seconds)
based on 100 simulations with 25 initial values per simulation. Quantiles are based on the
pooled sample of 2,500 computation times for all methods except for JADE, which is not
initialized with multiple starting values and is consequently based on 100 samples.
Q
5
5
5
10
10
10
20
20
20

Quantile
0.025
0.500
0.975
0.025
0.500
0.975
0.025
0.500
0.975

FastICA
0.01
0.03
1.58
0.04
0.34
2.85
1.11
7.46
27.07

Infomax
1.28
3.19
5.95
5.88
11.69
13.05
18.75
25.36
29.02

JADE
0.02
0.02
0.05
0.10
0.17
0.27
2.41
3.98
10.00

ProDenICA
3.43
5.84
30.67
11.70
28.75
267.23
95.66
544.92
2478.45

A.4 Notes on the Minimum Distance Measure
We adapt the minimum distance (MD) measure (Ilmonen et al. 2010), which was defined for
c (i) when the true unmixing matrix, W, is known. We apply the measure
some estimate W
to two arbitrary square matrices B(i) and B(j) . Let P denote the set of Q × Q signed
permutation matrices and C the set of Q × Q full-rank diagonal matrices. Then define the
set of scaled permutation matrices K = {K : K = P± C, ∀ P± ∈ P, C ∈ C}. Then the
minimum distance measure between two matrices B(i) and B(j) is

dM D (B(i) , B(j) ) = √

1
inf || KB(i) B−1
(j) − Id ||F
Q − 1 K∈K

where || · ||F denotes the Frobenius norm. Code implementing this measure is available in
the R package JADE (Nordhausen et al. 2011).

A.5 Computation times
We conducted our simulations on a cluster of 28 Dell PowerEdge 2650 servers with 8
processors per server, where each processor was 2.66 GHz. We used the R package snow
(Tierney et al. 2011) to conduct simulations in parallel. Computation times are presented
in Web Table 1.

4

Web Appendix B: Matching ICs
Our approach to matching ICs follows a modification of the Hungarian (Kuhn-Munkres)
algorithm (Tichavsky and Koldovsky 2004), and here we describe the algorithm in detail.
b k ∈ RV ×Q and S
b l ∈ RV ×Q , the ith estimate from method
Suppose we want to compare S
(i)
(j)
k and the jth estimate from method l. Hereafter, we drop the k and l superscripts to
simplify notation, noting that the estimates may or may not be from the same method.
b (i) is in canonical form, as defined in Section 4.2. We refer to the canonically
Assume that S
b (i) as the template. Let S
b (i),q be the qth column of S
b (i) and S
b (j),r be the rth
ordered S
b (j) , and let || · || denote the Euclidean norm. Create a Q × Q distance matrix
column from S
B between the components with elements


b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || ,
bq,r = min ||S

and define the matrix C with

cq,r




−1



b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || = ||S
b (i),q + S
b (j),r ||,
if min ||S
=




b (i),q − S
b (j),r ||, ||S
b (i),q + S
b (j),r || = ||S
b (i),q − S
b (j),r ||.
 1 if min ||S

Let A be the set of all permutations of the integers 1 to Q, where for some A ∈ A,
A = {a1 , . . . , aQ }. We then use the Hungarian method (Kuhn 1955) to identify the set such
that
A1 = argmin
A∈A

Q
X

bq,aq .

q=1

Then define the signed permutation matrix P1 with entries pq,aq = cq,aq at row q and
b (i) − S
b (j) P0 ||F .
column aq , and 0 otherwise. Note that P1 is equivalent to argmin || S
±
P± ∈P

The method used here to match ICs creates a one-to-one mapping of components. Note
that when multiple ICs are being compared, the matching algorithm may be sensitive to
the choice of template. In our application, we found that using the estimates from JADE,
Infomax, or ProDenICA as the template with one-at-a-time matching resulted in the same
ordering as using the FastICA estimate as the template. In situations in which ICs from
more than two estimates differ greatly, a method to simultaneously match all ICs could be
5

Web Table 2. Subject diagnosis by site in the ADHD-200 Sample: Typ=Typically Developing; ADHD-C=ADHD-Combined; ADHD-H/Im=ADHD-Hyperactive and Impulsive;
ADHD-In=ADHD-Inattentive; WH= Withheld.
Site
Bradley Hospital/Brown University
Kennedy Krieger Institute
NeuroIMAGE Sample
NYU Child Study Center
Oregon Health & Science University
Peking University
University of Pittsburgh
Washington University in St. Louis
Total

Typ
0
61
23
99
42
116
89
61
491

ADHD-C
0
16
18
77
23
29
0
0
163

ADHD-H/Im
0
1
6
2
2
0
0
0
11

ADHD-In
0
5
1
44
12
49
0
0
111

WH
26
11
25
41
34
51
9
0
197

pursued.

Web Appendix C: Group ICA of the ADHD-200 Sample
C.1 Motivating dataset
Data were selected for analysis from the ADHD-200 Data Sample, which consists of rsfMRI data from children and adolescents (ages 7-21) from 8 independent sites comprising
491 typically developing subjects and 285 that were diagnosed with ADHD (Web Table 1).
Subjects were diagnosed with three ADHD subtypes: Inattentive; Hyperactive and Impulsive; and Combined (Hyperactive/Impulsive and Inattentive). However, there were only a
total of 11 subjects with ADHD-Inattentive, and half the sites did not have subjects with
this diagnosis.
We restricted our analysis to (1) subjects with no recorded history of drug therapy;
(2) subjects that were right-hand dominant; (3) images with no quality control flags; and
(4) subjects that were either ADHD-Combined or ADHD-Inattentive (but not ADHDHyperactive and Impulsive). Subjects were classified using either (1) the ADHD Rating
Scale IV, (2) Conner’s Parent Rating Scale-Revised (Long Version), or (3) Conner’s Rating
Scale, 3rd edition. Within these scales, there was a small degree of overlap in the intermediate values between subjects diagnosed as typically developing and subjects diagnosed
with ADHD, whereas individuals with low values were strictly labeled typically developing

6

Web Table 3. Subjects used in analysis. Typ=Typically Developing; ADHD-C=ADHDCombined; ADHD-In=ADHD-Inattentive.
Site
Peking University
Kennedy Krieger Institute
NYU Child Study Center
Oregon Health & Science University
Others
Total

Typ
86
40
56
24
0
206

ADHD-C
13
7
16
8
0
44

ADHD-H/Im
0
0
0
0
0
0

ADHD-In
19
3
11
1
0
34

WH
0
0
0
0
0
0

and individuals with high values were strictly diagnosed with ADHD. We excluded subjects
with scores that we deemed borderline, that is, both control and ADHD subjects that were
near the threshold at which ADHD was diagnosed. Specifically, we excluded subjects with
ADHD Rating Scale IV values between 36 and 45; Conner’s Parent Rating Scale-Revised
(Long Version) between 56 and 65; or Conner’s Rating Scale between 55 and 66 (Web Table
2).
Details of the primary image processing pipeline were previously reported (Section 2.1,
Eloyan et al. 2012). Processing followed the functional connectome processing scripts on
the FCP/INDI site (Mennes et al. 2012). In addition, we aggregated the MNI 152 T1 3 mm
template to result in 6 × 6 × 6 mm voxels. We retained the 6 × 6 × 6 mm voxels for which
all eight of the voxels in the MNI 152 T1 3mm template were brain tissue. This resulted in
V = 7, 825 for all subsequent analyses. For subjects in which there were multiple scanning
sessions, we only used the first session.
We also used our own whitening function to produce the input data for all algorithms,
as provided in <EvaluatingICA_Rsources.R>. This ensured that Ŵ and Ŝ were always
defined equivalently. Note that the functions fastICA and JADE automatically whiten
data; consequently, we modified the source code to prevent additional whitening.

C.2 Differences Between Algorithms
In Web Table 4, we present false discovery rate (FDR) adjusted p-values from two-sample
Kolmogorov-Smirnov tests for equality in distribution between ICs estimated using the
SVD, FastICA, Infomax, and ProDenICA. In multiple hypothesis testing, the FDR is the
expected proportion of false positives among the rejected null hypotheses, and controlling
7

the FDR leads to more powerful testing procedures than controlling the family-wise error
rate (Benjamini and Hochberg 1995). For each p-value, we calculated an FDR-adjusted
p-value, called a q-value (Storey 2002): let G denote the total number of tests and p(g)
denote the gth order statistic from the set of all G p-values, and define the q-value
p∗(g)


= min


G
∗
∗
p ,p
, . . . , p(G) , 1 .
g (g) (g+1)

In typical applications, p∗(g) is an estimate of the minimum proportion of false positives given
that at least one rejection occurs, where the minimum is taken over all rejection regions
containing [0, p(g) ]. Here, we use the FDR-adjusted p-values as a measure of the difference
between IC distributions since the test statistics were based on spatially dependent data.
Web Table 4. FDR-adjusted p-values from two-sample Kolmogorov-Smirnov statistics.
Blank entries indicate FDR-adjusted p < 0.0001.
Method1
SVD
SVD
SVD
SVD
FastICA
FastICA
FastICA
Infomax
Infomax
JADE
Method1
SVD
SVD
SVD
SVD
FastICA
FastICA
FastICA
Infomax
Infomax
JADE

Method2
FastICA
Infomax
JADE
ProDenICA
Infomax
JADE
ProDenICA
JADE
ProDenICA
ProDenICA
Method2
FastICA
Infomax
JADE
ProDenICA
Infomax
JADE
ProDenICA
JADE
ProDenICA
ProDenICA

IC 1

IC 2

IC 3

0.9826
0.6165
0.0658
0.4688
0.1370
0.2807
IC 11

0.2733
0.0101
0.0166

0.1277

IC 12

IC 13

0.0878

0.4890
0.2136

0.3943

IC 4

IC 5

IC 6

IC 7

IC 8

IC 9

IC 10

0.5650
0.0001
0.1277

0.3543
0.0004
0.0002

0.4036
0.0222

0.1811

0.0005

IC 14

0.0556
0.2421
0.0451
0.1574
0.2354
0.0254
IC 15

IC 16

IC 17

0.1105
0.0003
0.0053
0.0004
0.0254
0.0265
IC 19

0.9481
0.0129
0.0129
0.0024
0.0027
0.1415
IC 20

0.3851
0.0380

0.9826
0.1068

0.4225
0.0101

0.0018
0.7906
0.1866

0.9826
0.0006

0.2867

0.4130

0.0112

0.0433

0.0002

0.0348

0.0002

0.4788

0.2660

0.9826
0.2867

0.0556
0.0002
IC 18
0.0004
0.0003
0.0002

0.0304

We also present density plots for each IC and each method. Densities were estimated
using a Gaussian kernel with bandwidths chosen using Silverman’s rule of thumb (Silverman
1986).

8

IC 2

IC 3

5

15

25

0

5

10

1.0
0.0

1.0

Density

Index

0.0

0.6
0.0

0.4
−5

IC 4

Index
Density

Index
Density

0.8

Index

0.0

Density

Density

IC 1

1

1

1

FastICA
Infomax
JADE
ProDenICA

1

Web Figure 2. Density plots of ICs for FastICA, Infomax, JADE, and ProDenICA. Values
on the x-axis correspond to the standardized BOLD signal.

−2

2

6

10

−2

2

4

6

8

−2

2 4 6 8

−4

0 2 4 6 8

0.0

0.6

Density

0.0

0.6

Density

0.0

0.6

Density

0.6
0.0

Density

Density

IC 5
IC 6
IC 7
IC 8
N = 7825 Bandwidth = 0.07641 N = 7825 Bandwidth = 0.07835 N = 7825 Bandwidth = 0.05468 N = 7825 Bandwidth = 0.05378

−2

2 4 6 8

−2

2

4

6

8

−4

0 2 4 6 8

−2

IC 13

0

2

4

6

0.6
0.0

Density

0.0 0.6 1.2

Density

0.0

0.6

Density

0.6
0.0

Density

Density

IC 9
IC 10
IC 11
IC 12
N = 7825 Bandwidth = 0.06816 N = 7825 Bandwidth = 0.07392 N = 7825 Bandwidth = 0.07392 N = 7825 Bandwidth = 0.06191

−6

−2

IC 14

2 4 6

−2

IC 15

2

4

6

8

IC 16

−4

0

2

4

6

−4

0

2

4

6

−4

0

2

4

0.0 0.3 0.6

Density

0.0 0.3 0.6

Density

0.0

0.4

Density

0.8
0.4
0.0

Density

Density

N = 7825 Bandwidth = 0.08189 N = 7825 Bandwidth = 0.0633 N = 7825 Bandwidth = 0.06551 N = 7825 Bandwidth = 0.07603

6

−6

−2

2 4 6

0

2

4

Std. BOLD

6

−5

0

5

−5

Std. BOLD

0

5

0.0 0.4 0.8

Density

0.8

−4

0.0

0.4

Density

0.0

0.4

Density

0.4
0.0

Density

Density

IC 17
IC 18
IC 19
IC 20
N = 7825 Bandwidth = 0.1065 N = 7825 Bandwidth = 0.09457 N = 7825 Bandwidth = 0.1101 N = 7825 Bandwidth = 0.1075

−6

Std. BOLD

−2

2 4 6

Std. BOLD

N = 7825 Bandwidth = 0.09591 N = 7825 Bandwidth = 0.1138 N = 7825 Bandwidth = 0.09827 N = 7825 Bandwidth = 0.07986

References
A.J. Bell and T.J. Sejnowski. An information-maximization approach to blind separation
and blind deconvolution. Neural computation, 7(6):1129–1159, 1995.
Y. Benjamini and Y. Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B
(Methodological), pages 289–300, 1995.
9

C.A. Bernaards and R.I. Jennrich. Gradient projection algorithms and software for arbitrary
rotation criteria in factor analysis. Educational and Psychological Measurement, 65(5):
676–696, 2005.
A. Eloyan, J. Muschelli, M.B. Nebel, H. Liu, F. Han, T. Zhao, A. Barber, S. Joel, J.J.
Pekar, S Mostofsky, and B. Caffo. Automated diagnoses of attention deficit hyperactive
disorder using magnetic resonance imaging. Frontiers in Systems Neuroscience, 6:1–9,
2012.
T. Hastie and R. Tibshirani. ProDenICA: Product Density Estimation for ICA using
tilted Gaussian density estimates, 2010. URL http://CRAN.R-project.org/package=
ProDenICA. R package version 1.0.
P. Ilmonen, K. Nordhausen, H. Oja, and E. Ollila. A new performance index for ICA:
properties, computation and asymptotic analysis. Latent Variable Analysis and Signal
Separation, pages 229–236, 2010.
H.W. Kuhn. The Hungarian Method for the assignment problem. Naval Research Logistics
Quarterly, 2:83 – 97, 1955.
M. Mennes, B. Biswal, F.X. Castellanos, and M.P. Milham. Making data sharing work:
The FCP/INDI experience. NeuroImage, 2012.
K. Nordhausen, J.F. Cardoso, H. Oja, and E. Ollila. JADE: JADE and ICA performance
criteria, 2011. URL http://CRAN.R-project.org/package=JADE. R package version
1.0-4.
B.W. Silverman. Density estimation for statistics and data analysis, volume 26. Chapman
& Hall/CRC, 1986.
J.D. Storey. A direct approach to false discovery rates. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 64(3):479–498, 2002.
P. Tichavsky and Z. Koldovsky. Optimal pairing of signal components separated by blind
techniques. Signal Processing Letters, IEEE, 11(2):119–122, 2004.

10

L. Tierney, A. J. Rossini, N. Li, and H. Sevcikova. snow: Simple Network of Workstations,
2011. URL http://CRAN.R-project.org/package=snow. R package version 0.3-8.

11

