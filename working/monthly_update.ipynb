{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Update\n",
    "October 2, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "ancestor = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if ancestor not in sys.path:\n",
    "    sys.path.append(ancestor)\n",
    "from Biblio_Reader import manager as mg\n",
    "from Biblio_Reader.biblio_reader import pdf_utils\n",
    "from Biblio_Reader.biblio_reader import pub_med\n",
    "from Biblio_Reader.biblio_reader.text_tools import convertToText, text_tools\n",
    "initial_date = date(2017, 3, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytd = '../outputs/FCP_DATA_updated_{0}.csv'.format(date.today().year)\n",
    "existing = pd.read_csv(ytd) if os.path.exists(ytd) else pd.read_csv('../outputs/FCP_DATA.csv')\n",
    "if not os.path.exists(ytd):\n",
    "    existing['DateAdded'] = initial_date\n",
    "existing.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load today's data…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = pd.read_csv(os.path.join('../outputs', '{0}.csv'.format(str(date.today()))))\n",
    "today['DateAdded'] = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercase, stripped titles for comparison…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today_lower = today.copy()\n",
    "existing_lower = existing.copy()\n",
    "today_lower['Title'] = today_lower['Title'].apply(lambda x: x.strip().lower())\n",
    "existing_lower['Title'] = existing_lower['Title'].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today_lower = today_lower.loc[~today_lower.duplicated(subset=['URL'])]  # internal dupes by URL\n",
    "today_lower = today_lower.loc[~today_lower.duplicated(subset=['Title'])]  # internal dupes by Title\n",
    "today_lower = today_lower.loc[~today_lower['URL'].isin(existing_lower['URL'])]  # cross-csv dupes by URL\n",
    "today_lower = today_lower.loc[~today_lower['Title'].isin(existing_lower['Title'])]  # cross-csv dupes by Title\n",
    "today = today[today['Unnamed: 0'].isin(today_lower['Unnamed: 0'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually check for straggling duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(today['Title'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what preprints have since been published…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprints_and_others = existing_lower[existing_lower['Journal Category'].isin(['Other', 'Preprint'])]\n",
    "preprints = existing_lower[existing_lower['Journal Category'] == 'Preprint']\n",
    "potentials = list(set(today_lower.loc[today_lower['Title'].isin(preprints_and_others['Title'])]['Title']\n",
    "                ) | set(today_lower.loc[today_lower['Authors'].isin(preprints_and_others['Authors'])]['Title']))\n",
    "print(potentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today['i'] = range(max(existing['i']) + 1, max(existing['i']) + 1 + today.shape[0])\n",
    "today = today.drop('Unnamed: 0', axis=1)\n",
    "today.index = today.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today_dir = os.path.abspath(os.path.join(ancestor, 'Biblio_Reader', str(date.today())))\n",
    "if not os.path.exists(today_dir):\n",
    "    os.makedirs(today_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PubMed IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today['PMCID'] = pub_med.get_ids(today)\n",
    "today_pubmed = os.path.join(mg.WORKING_PATH, str(date.today()))\n",
    "if not os.path.exists(today_pubmed):\n",
    "    os.makedirs(today_pubmed)\n",
    "pub_med.write_bib(today, today_pubmed)\n",
    "pub_med.parse_bib(today_pubmed, \"{0}_bibs.csv\".format(today_pubmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.pdffinder(\n",
    "    zip(today['i'], today['URL']),\n",
    "    today_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.pdfopener(today, today_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.arxiv_open(zip(today['i'], today['URL']),\n",
    "    today_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.plos_open(zip(today['i'], today['URL']),\n",
    "    today_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.liebert_open(zip(today['i'], today['URL']),\n",
    "    today_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pdf_utils.citeseer_open(zip(today['i'], today['URL']),\n",
    "    today_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually download as many of these as you can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_nots = set(pdf_utils.find_corrupted(today_dir))\n",
    "haves = [int(i.rstrip('.pdf')) for i in os.listdir(today_dir) if i.endswith('pdf')]\n",
    "have_nots = ({i for i in today['i'] if i not in haves} | have_nots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in have_nots:\n",
    "    path = today['URL']\n",
    "    path = path.apply(lambda x: x[26:] if x.startswith('http://scholar.google.com/') else x)\n",
    "    print(i, end=\" : \")\n",
    "    print(path[i], end=\" : \")\n",
    "    print(today['Title'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_nots = set(pdf_utils.find_corrupted(today_dir))\n",
    "haves = [int(i.rstrip('.pdf')) for i in os.listdir(today_dir) if i.endswith('pdf')]\n",
    "have_nots = ({i for i in today['i'] if i not in haves} | have_nots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in have_nots:\n",
    "    path = today['URL']\n",
    "    path = path.apply(\n",
    "           lambda x:\n",
    "               x[26:] if x.startswith('http://scholar.google.com/') else x\n",
    "           )\n",
    "    print(i, end=\" : \")\n",
    "    print(path[i], end=\" : \")\n",
    "    print(today['Title'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading pdfs, convert to plaintext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_dir = os.path.join(today_dir, 'txt')\n",
    "if not os.path.exists(txt_dir):\n",
    "    os.makedirs(txt_dir)\n",
    "convertToText.walkAndText(today_dir, txt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect relevant ¶s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today['Excerpt'] = pd.Series(\n",
    "                       text_tools.find_paragraphs(\n",
    "                           txt_dir,\n",
    "                           [*mg.WEIGHTED_SETS, *mg.UNWEIGHTED_SETS],\n",
    "                           os.path.join(today_dir, 'excerpts')\n",
    "                       )\n",
    "                   ).apply(lambda x: \"\\n\\n\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = text_tools.assoc_sets(\n",
    "            today,\n",
    "            txt_dir,\n",
    "            mg.WEIGHTED_SETS,\n",
    "            mg.UNWEIGHTED_SETS\n",
    "        )\n",
    "today['Sets'] = pd.Series(\n",
    "    {k:sets[k]\n",
    "        for k in sets if k>=min(today['i'])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "existing.merge(today, how='outer').to_csv(ytd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vet what's left on the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_utils.find_articles_left(\n",
    "    zip(today['i'].astype(str), today['URL']),\n",
    "    txt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human-readable excerpt txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(today_dir, 'excerpts.txt'), 'w') as f:\n",
    "    f.write(\"\".join([\"{0}\\n\\n{1}\\n\\n\\n\\n\".format(i, j)\n",
    "        for i, j in zip(today.index, today['Excerpt'])])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come back after all the manual vetting and run the numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'i', 'Title', 'URL', 'Year', 'Citations', 'Versions',\n",
       "       'Cluster ID', 'PDF link', 'Citations list', 'Versions list',\n",
       "       'Citation link', 'Excerpt', 'Journal', 'Authors', 'Publisher',\n",
       "       'Citations Per Year', 'Journal Category', 'PMCID', 'Affiliations',\n",
       "       'Qualifiers', 'Data Use', 'Sets', 'Contributor', 'Duplicate of',\n",
       "       'DateAdded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing.loc[\n",
    "    (existing['Data Use'].isin(['Y', 'N'])) &\n",
    "    (existing['Contributor'] == 'Contributor')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing.loc[\n",
    "    (existing['Journal Category'] == 'Journal') & \n",
    "    (existing['Data Use'].isin(['Y'])) &\n",
    "    (existing['Contributor'] == 'Contributor')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing.loc[\n",
    "    (existing['Data Use'].isin(['Y', 'N'])) &\n",
    "    (existing['Contributor'] == 'Not a Contributor')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing.loc[\n",
    "    ((existing['Journal Category'] == 'Journal') |\n",
    "     (existing['Qualifiers'] == 'peer-reviewed')) & \n",
    "    (existing['Data Use'].isin(['Y', 'S', 'N'])) &\n",
    "    (existing['Contributor'] == 'Not a Contributor')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing.loc[\n",
    "    ((existing['Journal Category'] == 'Journal') |\n",
    "     (existing['Qualifiers'] == 'peer-reviewed')) & \n",
    "    (existing['Data Use'].isin(['Y', 'S', 'N']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1442"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing.loc[\n",
    "    (existing['Data Use'].isin(['Y', 'N']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing.loc[    \n",
    "    (existing['Journal Category'] == 'Journal') & \n",
    "    (existing['Data Use'].isin(['Y', 'N']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
